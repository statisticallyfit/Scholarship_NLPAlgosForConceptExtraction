


\begin{frame}{}
    \begin{center}
        \large \textbf{XLNet}
    \end{center}
    \vspace{20pt}
    
    \textbf{Author(s):}
    \begin{itemizeSpaced}{5pt}
    {\color{DimGrey} 
    
        \item Yang et al. (2020) in \emph{XLNet: Generalized Autoregressive Pretraining for Language Understanding}
        
    }
    \end{itemizeSpaced}
\end{frame}

% -------------------------------------------------



\begin{frame}{XLNet: Problems with BERT}

\begin{itemizeSpaced}{10pt}
    \item An \textbf{autoregressive language model (AR)} estimates the probability distribution of a text sequence by factorizing a likelihood using tokens \emph{before} a timestep, or tokens \emph{after} a timestep $\Rightarrow$ cannot model bidirectional context. 
    
    \item An \textbf{autoencoding language model (AE)} like BERT is a masked language model $\Rightarrow$ does not estimate densities like AR $\Rightarrow$ can learn bidirectional contexts. 
    
    \pinkbox \textbf{BERT's problems: }
    \begin{itemizeSpaced}{10pt}
        
        \item \textbf{False Independence Assumption: } BERT factorizes its log likelihood probability \alert{assuming all masked tokens are rebuilt independently of each other (so BERT ignores long-term dependencies within texts)}
        
        \item \textbf{Data Corruption: }Masked tokens do not appear in real data during fine-tuning, so since BERT uses them in pre-training, a \alert{discrepancy} arises between these two steps. 
    \end{itemizeSpaced}
    
    
\end{itemizeSpaced}


    
\end{frame}


\begin{frame}{XLNet: Example of BERT's False Independence Assumption}
    
    \vspace{10pt}
    
    \begin{exampleBlock}{Example: BERT predicting tokens independently}
    \footnotesize 
    
    ``I went to the \texttt{[MASK]} \texttt{[MASK]} and saw the \texttt{[MASK]} \texttt{[MASK]} \texttt{[MASK]}." \newline 
    
    Two ways to fill this are: \newline
    
    ``I went to \underline{New York} and saw the \underline{Empire State building}," or\newline
    
    ``I went to \underline{San Francisco} and saw the \underline{Golden Gate bridge}."\newline
    
    But BERT might incorrectly predict something like: ``I went to \underline{San Francisco} and saw the \underline{Empire State building}." \newline
    
    Independence assumption + predicting masked tokens simultaneously $\Rightarrow$ BERT fails to learn their interlocking dependencies $\Rightarrow$ weakens the ``learning signal" (Kurita, 2019b). 
    \end{exampleBlock}

\end{frame}


\begin{frame}{XLNet: Motivation}

    \footnotesize 
    
    To keep benefits of both autoencoding and autoregressive modeling while avoiding their issues...
    
    \begin{enumerateSpaced}{7pt}
    
        \footnotesize  
    
        \item XLNet adopts an AR model so that probability of a token can be factored with \emph{universal probability rule}, {\color{DodgerBlue}  \textbf{avoiding BERT's false independence assumption}}. 
        
        \item XLNet uses \textbf{permutation language model}:
        
        \begin{itemizeSpaced}{15pt}
           % \vspace{7pt}
            
            \footnotesize  
            
            \item \textbf{Permutation language model:} predicts unidirectionally but in \emph{random order}. 
            
            \item Forced to {\color{DodgerBlue} \textbf{accumulate bidirectional context}} by finding dependencies between \emph{all} possible input combinations.
        \end{itemizeSpaced}
        
        
        % AND \textbf{two-stream attention} to adapt its Transformer to create target-aware predictions. 
    \end{enumerateSpaced}
    
\end{frame}


% 
% \begin{frame}{XLNet: Permutation Language Model}
%     
%     \vspace{10pt}
%     
%     
%     \footnotesize 
%     
%     \textbf{Created so that: } a model can be trained to use \textbf{bidirectional context} while avoiding masking and its resulting problem of independent predictions.
% 
%     \begin{definitionBlock}{Definition: Permutation Language Model}
%     Like language models, a \textbf{permutation language model} predicts unidirectionally but in \emph{random order}. \newline 
%     
%     \emph{Forced to accumulate bidirectional context by finding dependencies between \emph{all} possible input combinations.} \newline 
%     
%     (NOTE: only permutes factorization order, not order of word inputs)
%     \end{definitionBlock}
%     
% \end{frame}


\begin{frame}{XLNet: Target-Aware Predictions}

    \vspace{10pt}

    \begin{itemizeSpaced}{10pt}
        \footnotesize 
        
        \pinkbox {\color{Crimson} \textbf{Problem: }} Merging permutation model with Transformer blinded XLNetâ€™s target predictions.
        
        \begin{itemizeSpaced}{0pt}
            \footnotesize 
            \item {\color{Crimson} \textbf{Reason: Transformer is at fault! }}during prediction, Transformer masks a token's embedding (normal) but also masks a token's \emph{positional encoding} (bad!)
        \end{itemizeSpaced}

        
        %$\Rightarrow$  sentence cannot be accurately represented (since positions like the beginning of a sentence have different distributions from other positions in the sentence.)
        
        \item {\color{ForestGreen} \textbf{Solution: Target-awareness: }} now, predictive distribution takes target position as argument $\Rightarrow$ creates target-aware embeddings. 
        
        %\pinkbox {\color{Crimson} \textbf{Another problem}: }Transformer nature makes contradiction: (1) to predict the content token $x_{z_t}$, only the position is needed, not the content $x_{z_t}$, and (2) to predict all other tokens $x_{z_j}$, the content token is  needed. 
        
        \item {\color{ForestGreen} \textbf{Two-Stream Attention Mechanism: }}uses two separate hidden states to take target and position tokens separately:
        
        
        \vspace{5pt}
        \begin{itemizeSpaced}{5pt}
            \footnotesize 
            
            \item \textbf{Content-Stream Attention: } takes \emph{context} and \emph{content} (prediction) token $x_{z_t}$ (like ordinary Transformer)
            
            \item \textbf{Query-Stream Attention: }takes \emph{context} and target's \emph{position} but NOT content (prediction) $x_{z_t}$ (to evade the contradiction). 
        \end{itemizeSpaced} 
        
    \end{itemizeSpaced}
\end{frame}

% 
% \begin{frame}{XLNet: Relative Segment Encodings}
%     \small XLNet adopts Transformer-XL's idea of relative encodings ... 
%     
%     \begin{itemizeSpaced}{10pt}
%         \small 
%         \item BERT's segment embeddings distinguish words belonging to different segments. 
%         
%         \pinkbox XLNet's segment embeddings encode if two words are \emph{within the same segment} rather than \emph{which specific segments the words are from} $\Rightarrow$ can apply XLNet to tasks that intake arbitrarily many sequences. 
%     \end{itemizeSpaced}
%     
% \end{frame}


\begin{frame}{XLNet: Conceptual Difference with BERT}

    \vspace{20pt}
    
    \begin{exampleBlock}{Example: Conceptual Difference between XLNet and BERT}
    

    Take the list of words $\Big[ \texttt{New}, \texttt{York}, \texttt{is}, \texttt{a}, \texttt{city} \Big]$. 
    
    Prediction tokens: $\Big[ \texttt{New}, \texttt{York} \Big]$ 
    
    XLNet and BERT must maximize the log-likelihood: $\text{log} \; P(\texttt{New York} \; | \; \texttt{is a city})$. 
    
    Assumption: XLNet uses the factorization order $\Big[ \texttt{is}, \texttt{a}, \texttt{city}, \texttt{New}, \texttt{York} \Big]$
    
    Then each of their loss functions are: 
    
    \begin{equation}
    \begin{array}{ll}
    \mathcal{J}_\text{BERT} = \text{log} \; P \Big( \texttt{New} \; | \; \texttt{is a city} \Big) \; + \; \text{log} \; P \Big( \texttt{York} \; | \; \texttt{is a city} \Big) \\
    \mathcal{J}_\text{XLNet} = \text{log} \; P \Big( \texttt{New} \; | \; \texttt{is a city} \Big) \; + \; \text{log} \; P \Big( \texttt{York} \; | \; {\color{cyan} \texttt{New}}, \texttt{is a city} \Big) 
    \end{array}
    \end{equation}
    
    Result: XLNet learns a stronger dependency than BERT between the pairs \texttt{New} and \texttt{York} (Dai et al., 2019). 
    
    \end{exampleBlock}
    
\end{frame}