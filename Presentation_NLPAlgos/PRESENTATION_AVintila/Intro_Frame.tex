
\section{Introduction: Motivation for Text Processing}


\begin{frame}{Introduction: Motivation for Text Processing}



\begin{itemizeSpaced}{5pt}

    \pinkbox Knowledge is trapped in media like html, pdfs, paper as opposed to being concept-mapped, interlinked, addressable and reusable at fine grained levels.
    
    \pinkbox Defeats exchanges between humans and AI.
    
    %\pinkbox Fact: concept mapping enhances human cognition. 
    
    \pinkbox Especially in domain-specific areas of knowledge, better interlinking would be achieved if concepts would be extracted using surrounding context, accounting for polysemy and key phrases.
    
    \item {\color{Maroon} \emph{“You shall know a word by the company it keeps”} (Firth, 1957).}
    
    
    \pinkbox Previous models GloVe and Word2Vec motivated recent ones to move beyond simple co-occurrence counts to extract meaning. 
    
    \item ERNIE 2.0 instead “broadens the vision to include more lexical, syntactic and semantic information from training corpora in form of \textbf{named entities} (like person names, location names, and organization names), \textbf{semantic closeness} (proximity of sentences), \textbf{sentence order or discourse relations}” (Sun et al., 2019). 
    
    
    \pinkbox \textbf{Aim of This Project: } To understand how models make good language representations by inventorying {\color{MediumVioletRed} Transformer, ELMo, BERT, Transformer-XL, XLNet}, and {\color{MediumVioletRed} ERNIE 1.0} in how they leverage entities, polysemy, context for concept extraction. 
    
    
\end{itemizeSpaced}
\end{frame}






% ERASE: 

% \begin{frame}{Aim of this Project}
% 
% To understand how good language representations are created using lexical and semantic structure, at the \emph{entity and phrase level}, using two approaches:
%     
% \vspace{15pt}
% 
% \begin{itemizeSpaced}{15pt}
%     \item \textbf{``Study"} to inventory, compare various architectures and how they leverage entities, polysemy, context for concept extraction. 
%     
%     \item \textbf{``Application"} using PyTorch to illustrate a key model architecture as it is applied to machine translation (MT) task. 
% \end{itemizeSpaced}
%     
% \end{frame}
