

\section{XLNet}


\begin{frame}{XLNet: Problems with BERT}

\begin{itemizeSpaced}{7pt}
    \pinkbox An \textbf{autoregressive language model (AR)} autoregressively estimates the probability distribution of a text sequence by factorizing a likelihood using tokens \emph{before} a timestep, or tokens \emph{after} a timestep. A neural network is trained to model either the forward or backward distribution $\Rightarrow$ cannot model bidirectional context. 
    
    \item An \textbf{autoencoding language model (AE)} like BERT is like a masked language model. It masks tokens, predicts them and does not estimate densities like AR $\Rightarrow$ can learn bidirectional contexts. 
    
    \pinkbox \textbf{BERT's problems: }
    \begin{itemizeSpaced}{7pt}
        
        \item \textbf{False Independence Assumption: } BERT factorizes its log likelihood probability assuming all masked tokens are rebuilt independently of each other (so BERT ignores long-term dependencies within texts)
        
        \item \textbf{Data Corruption: }Masked tokens do not appear in real data during fine-tuning, so since BERT uses them in pre-training, a discrepancy arises between these two steps. 
    \end{itemizeSpaced}
    
    
\end{itemizeSpaced}


    
\end{frame}


\begin{frame}{XLNet: Example of BERT's False Independence Assumption}
    
\begin{exampleBlock}{Example: BERT predicting tokens independently}
``I went to the \texttt{[MASK]} \texttt{[MASK]} and saw the \texttt{[MASK]} \texttt{[MASK]} \texttt{[MASK]}." 

Two ways to fill this are: 

``I went to \emph{New York} and saw the \textit{Empire State building}," or

``I went to \emph{San Francisco} and saw the \emph{Golden Gate bridge}."

But BERT might incorrectly predict something like: ``I went to \emph{San Francisco} and saw the \emph{Empire State building}." 

Independence assumption + predicting masked tokens simultaneously $\Rightarrow$ BERT fails to learn their interlocking dependencies $\Rightarrow$ weakens the ``learning signal" (Kurita, 2019b). 
\end{exampleBlock}

\end{frame}


\begin{frame}{XLNet: Motivation}

\large 

To keep benefits of both autoencoding and autoregressive modeling while avoiding their issues...

\begin{enumerateSpaced}{7pt}
    \item XLNet adopts an AR model so that probability of a token can be factored via product rule, eliminating BERT's false independence assumption. 
    
    \item XLNet uses \textbf{permutation language model} to capture bidirectional context AND \textbf{two-stream attention} to adapt its Transformer to create target-aware predictions. 
\end{enumerateSpaced}
    
\end{frame}



\begin{frame}{XLNet; Permutation Language Model}
    
    
    \textbf{Created so that: } a model can be trained to use \textbf{bidirectional context} while avoiding masking and its resulting problem of independent predictions.

    \vspace{20pt}
    
    \begin{definitionBlock}{Definition: Permutation Language Model}
    Like language models, a \textbf{permutation language model} predicts unidirectionally. 
    
    But instead of predicting in order, the model predicts tokens in a random order. 
    
    Is forced to accumulate bidirectional context by finding dependencies between \emph{all} possible input combinations. 
    
    (NOTE: only permutes factorization order, not order of word inputs)
    \end{definitionBlock}
    
\end{frame}


\begin{frame}{XLNet: Target-Aware Predictions}
    \begin{itemizeSpaced}{5pt}
        \item {\color{Crimson} \textbf{Problem: }} Trying to merge permutation language model and Transformer made XLNet’s target predictions blind to the permutation positions generated by the permutation language model.

        \item Fault is due to Transformer: while predicting a token at a position, the model masks the token’s embedding AND also its \emph{positional} encoding $\Rightarrow$ Transformer remains blind about the position of the target it should be predicting $\Rightarrow$  sentence cannot be accurately represented (since positions like the beginning of a sentence have different distributions from other positions in the sentence.)
        
        \item {\color{ForestGreen} \textbf{Solution: Target-awareness: }} authors adapted the predictive distribution to take the target position as an argument $\Rightarrow$ now can create target-aware embeddings. 
        
        \item {\color{Crimson} \textbf{Another problem}: }aforementioned problem with Transformer creates a contradiction: (1) to predict the content token $x_{z_t}$, only the position is needed, not the content $x_{z_t}$, and (2) to predict all other tokens $x_{z_j}$, the content token is  needed. 
        
        \item {\color{ForestGreen} \textbf{Two-Stream Attention: }}uses two sets of hidden states (content stream and query stream) to create an overall hidden state. 
        
        {\linespread{0.3}
        \begin{itemizeSpaced}{5pt}
            \item \textbf{Content-Stream Attention: } encodes \emph{context} like an ordinary Transformer, along with the \emph{content} (prediction) token $x_{z_t}$
            
            \item \textbf{Query-Stream Attention: }encodes \emph{context} with target token's \emph{position} but NOT content (prediction) token $x_{z_t}$ (to evade the contradiction). 
        \end{itemizeSpaced} }
        
    \end{itemizeSpaced}
\end{frame}


\begin{frame}{XLNet: Relative Segment Encodings}
    \normalsize
    \begin{itemizeSpaced}{10pt}
        \item XLNet adopts Transformer-XL's idea of relative encodings. 
        
        \item BERT's segment embeddings distinguish words belonging to different segments. 
        
        \pinkbox XLNet's segment embeddings encode if two words are \emph{within the same segment} rather than \emph{which specific segments the words are from} $\Rightarrow$ can apply XLNet to tasks that intake arbitrarily many sequences. 
    \end{itemizeSpaced}
    
\end{frame}


\begin{frame}{XLNet: Conceptual Difference with BERT}

Illustrating the conceptual difference between XLNet and BERT from a model training standpoint: 

    \begin{exampleBlock}{Example: Conceptual Difference between XLNet and BERT}
    

    Take the list of words $\Big[ \texttt{New}, \texttt{York}, \texttt{is}, \texttt{a}, \texttt{city} \Big]$. 
    
    Prediction tokens: $\Big[ \texttt{New}, \texttt{York} \Big]$ 
    
    XLNet and BERT must maximize the log-likelihood: $\text{log} \; P(\texttt{New York} \; | \; \texttt{is a city})$. 
    
    Assumption: XLNet uses the factorization order $\Big[ \texttt{is}, \texttt{a}, \texttt{city}, \texttt{New}, \texttt{York} \Big]$
    
    Then each of their loss functions are: 
    
    \begin{equation}
    \begin{array}{ll}
    \mathcal{J}_\text{BERT} = \text{log} \; P \Big( \texttt{New} \; | \; \texttt{is a city} \Big) \; + \; \text{log} \; P \Big( \texttt{York} \; | \; \texttt{is a city} \Big) \\
    \mathcal{J}_\text{XLNet} = \text{log} \; P \Big( \texttt{New} \; | \; \texttt{is a city} \Big) \; + \; \text{log} \; P \Big( \texttt{York} \; | \; {\color{cyan} \texttt{New}}, \texttt{is a city} \Big) 
    \end{array}
    \end{equation}
    
    Result: XLNet learns a stronger dependency than BERT between the pairs \texttt{New} and \texttt{York} (Dai et al., 2019). 
    
    \end{exampleBlock}
    
\end{frame}